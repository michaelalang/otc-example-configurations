apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: flapper
  namespace: openshift-logging
spec:
  mode: daemonset
  env:
    - name: KUBE_NODE_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: spec.nodeName
    - name: CLUSTERNAME
      value: "acm"
    - name: JOB
      value: "k8s_resource_flapper"
  tolerations:
  - key: node-role.kubernetes.io/master
    effect: NoSchedule
    operator: Exists

  serviceAccount: clfotlp
  securityContext:
    runAsUser: 0
    runAsGroup: 0
    fsGroup: 0
    allowPrivilegeEscalation: false
    capabilities:
      drop: [ALL]
    readOnlyRootFilesystem: true
    seLinuxOptions:
      type: spc_t
    seccompProfile:
      type: RuntimeDefault

  config:
    receivers:
      filelog/audit:
        include:
          - /host/var/log/openshift-apiserver/audit.log
          - /host/var/log/kube-apiserver/audit.log
        start_at: beginning
      filelog/hcpaudit:
        include:
          - /host/var/log/pods/*kube-apiserver*/audit-logs/0.log
          - /host/var/log/pods/*openshift-apiserver*/audit-logs/0.log
        include_file_name: false
        include_file_path: true
        operators:
        - type: container
        start_at: beginning
    processors:
      batch: {}
      transform/audit_parser:
        error_mode: ignore
        log_statements:
          - context: log
            statements:
              - set(log.body, ParseJSON(log.body)) where IsMatch(log.body, "^\\{")
              - set(resource.attributes["resource_name"], "n/a")
              - set(resource.attributes["resource_type"], "n/a")
              - set(resource.attributes["source_user"], "n/a")
              - set(resource.attributes["verb"], "n/a")
              - set(resource.attributes["resource_name"], log.body["objectRef"]["name"]) where log.body["objectRef"]["name"] != nil 
              - set(resource.attributes["resource_type"], log.body["objectRef"]["resource"]) where log.body["objectRef"]["resource"] != nil
              - set(resource.attributes["source_user"], log.body["user"]["username"]) where log.body["user"]["username"] != nil
              - set(resource.attributes["verb"], log.body["verb"]) where log.body["verb"] != nil
              - set(log.attributes["target_resource"], log.body["objectRef"]["resource"]) where log.body["objectRef"]["resource"] != nil
              - set(log.attributes["openshift_cluster_name"], "${CLUSTERNAME}")
      filter/audit_interest:
        error_mode: ignore
        logs:
          log_record:
            - 'log.attributes["target_resource"] == nil'
            - 'resource.attributes["verb"] != "update" and resource.attributes["verb"] != "patch"'
      transform/hostedcontrolplane:
        error_mode: ignore
        log_statements:
          - context: log
            statements:
              - set(resource.attributes["hosted_control_plane"], resource.attributes["k8s.namespace.name"])
              - replace_pattern(resource.attributes["hosted_control_plane"], "^([^-]+)-.*", "$1")

      transform/rename_metric:
        error_mode: ignore
        metric_statements:
          - context: datapoint
            statements:
              - set(metric.name, "k8s_resource_flapping") where metric.name == "log.record.count"
              - set(resource.attributes["job"], "${JOB}")
              - set(resource.attributes["cluster"], "${CLUSTERNAME}")
              - set(resource.attributes["openshift_cluster_name"], "${CLUSTERNAME}")
              - set(datapoint.attributes["resource_name"], "n/a")
              - set(datapoint.attributes["resource_type"], "n/a")
              - set(datapoint.attributes["source_user"], "n/a")
              - set(datapoint.attributes["verb"], "n/a")
              - set(datapoint.attributes["resource_name"], resource.attributes["resource_name"]) where resource.attributes["resource_name"] != nil
              - set(datapoint.attributes["resource_type"], resource.attributes["resource_type"]) where resource.attributes["resource_type"] != nil
              - set(datapoint.attributes["source_user"], resource.attributes["source_user"]) where resource.attributes["source_user"] != nil
              - set(datapoint.attributes["verb"], resource.attributes["verb"]) where resource.attributes["verb"] != nil
              - set(datapoint.attributes["target_resource"], resource.attributes["objectRef.resource"]) where IsMap(log.body) and log.body["objectRef"]["resource"] != nil
              - set(datapoint.attributes["cluster"], resource.attributes["hosted_control_plane"]) where resource.attributes["hosted_control_plane"] != nil
              - set(datapoint.attributes["cluster"], "${CLUSTERNAME}") where datapoint.attributes["cluster"] == nil

    connectors:
      count/flapping:
        metrics:
          log.record.count:
            description: Resource Flapping Tracker
            monotonic: true
            type: sum

    exporters:
      debug:
        verbosity: detailed
      otlphttp/prometheusremotewrite:
        endpoint: 'https://prometheus.apps.example.com/api/v1/otlp'
        tls:
          insecure_skip_verify: true
        timeout: 120s
        retry_on_failure:
          enabled: true
          initial_interval: 60s
          max_elapsed_time: 600s
          max_interval: 120s

    service:
      pipelines:
        logs:
          receivers: 
            - filelog/audit
          processors: 
            - transform/audit_parser
            - filter/audit_interest
          exporters: 
            - count/flapping
        logs/hcp:
          receivers:
            - filelog/hcpaudit
          processors:
            - transform/audit_parser
            - transform/hostedcontrolplane
            - filter/audit_interest
          exporters:
            - count/flapping
        metrics:
          receivers: 
            - count/flapping
          processors: 
            - batch
            - transform/rename_metric
          exporters: 
            - otlphttp/prometheusremotewrite
      telemetry:
        logs:
          level: info
        metrics:
          readers:
          - pull:
              exporter:
                prometheus:
                  host: 0.0.0.0
                  port: 8888
  volumes:
    - hostPath:
        path: /var/log/openshift-apiserver
      name: audit-ocp
    - hostPath:
        path: /var/log/kube-apiserver
      name: audit-k8s
    - hostPath:
        path: /var/hpvolumes/otc-queue
        type: DirectoryOrCreate
      name: otel-queue
    - hostPath:
        path: /var/log
      name: varlogpods
  
  volumeMounts:
    - mountPath: /host/var/log/openshift-apiserver
      name: audit-ocp
      readOnly: true
    - mountPath: /host/var/log/kube-apiserver
      name: audit-k8s
      readOnly: true
    - mountPath: /queues
      name: otel-queue
    - mountPath: /host/var/log
      name: varlogpods
      readOnly: true

